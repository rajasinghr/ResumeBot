{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "#import tflearn\n",
    "#import tensorflow as tf\n",
    "import random\n",
    "import nltk.corpus\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from flask import Flask, request, Response, render_template, jsonify\n",
    "import json\n",
    "import string\n",
    "import pickle\n",
    "from os import listdir\n",
    "import os\n",
    "import sqlite3\n",
    "import datetime\n",
    "import time\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('resume.db')\n",
    "c = conn.cursor()\n",
    "c.execute(\"select * from conversations where sessionId = 39\") #\"DELETE FROM conversations\"\n",
    "all_rows = c.fetchall()\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39,\n",
       "  'My name is Syed Azeem',\n",
       "  \"Hi Syed Azeem, Nice to meet you. You can ask questions to know about Raja Singh's professional career.\",\n",
       "  '',\n",
       "  '',\n",
       "  '2019-04-29 21:46:19.485733'),\n",
       " (39,\n",
       "  'That would be great',\n",
       "  'Please be specific, I am newly employed',\n",
       "  'unknown',\n",
       "  '',\n",
       "  '2019-04-29 21:46:33.245311'),\n",
       " (39,\n",
       "  \"What is the Raja Singh's educational background?\",\n",
       "  'Raja Singh Ravi, a graduate student from the University of South Florida.',\n",
       "  '',\n",
       "  'unknown',\n",
       "  '2019-04-29 21:47:38.979656'),\n",
       " (39,\n",
       "  'Where did he do his Bachelors?',\n",
       "  \"He is doing is Master's in Tampa, Florida\",\n",
       "  'master',\n",
       "  '',\n",
       "  '2019-04-29 21:48:03.039611'),\n",
       " (39,\n",
       "  ' Okay, but what about bachelors?',\n",
       "  'Please be specific, I am newly employed',\n",
       "  'unknown',\n",
       "  'master',\n",
       "  '2019-04-29 21:48:21.071184'),\n",
       " (39,\n",
       "  'From which year did he start working professionally?',\n",
       "  'Please be specific, I am newly employed',\n",
       "  'unknown',\n",
       "  'unknown',\n",
       "  '2019-04-29 21:48:51.016671'),\n",
       " (39,\n",
       "  'What are his primary skills?',\n",
       "  'He worked on the folllowing projects: <br/>1) Sentiment Analysis on E-Commerce user reviews, performing feature extraction and predicting feature ratings. <br/>2) Implemented a Knowledge Base Management System for classifying tickets using Python. <br/>3) Developed a reporting platform for generating and distributing reports. <br/>And his recent project is, <br/>4) Built chatbots using NLP packages in python.',\n",
       "  'projects',\n",
       "  'unknown',\n",
       "  '2019-04-29 21:49:06.062327'),\n",
       " (39,\n",
       "  'What was the most recent project he has worked on?',\n",
       "  'Raja Singh Ravi, a graduate student from the University of South Florida.',\n",
       "  '',\n",
       "  'projects',\n",
       "  '2019-04-29 21:49:35.761799'),\n",
       " (39,\n",
       "  'What is the projects Raja has worked on?',\n",
       "  'Raja Singh Ravi, a graduate student from the University of South Florida.',\n",
       "  '',\n",
       "  '',\n",
       "  '2019-04-29 21:50:11.942499'),\n",
       " (39,\n",
       "  \"What is the Raja Singh's educational background?\",\n",
       "  'His expected salary is $120k/year',\n",
       "  'salary',\n",
       "  '',\n",
       "  '2019-04-29 21:52:27.910405'),\n",
       " (39,\n",
       "  ' What is his educational background?',\n",
       "  'His expected salary is $120k/year',\n",
       "  'salary',\n",
       "  'salary',\n",
       "  '2019-04-29 21:52:43.810172'),\n",
       " (39,\n",
       "  ' What is his educational career?',\n",
       "  'His expected salary is $120k/year',\n",
       "  'salary',\n",
       "  'salary',\n",
       "  '2019-04-29 21:52:52.745606'),\n",
       " (39,\n",
       "  ' Educational career',\n",
       "  \"He is doing his Master's Degree at the University of South Florida, Tampa, Florida. <br/>He completed his Bachelor's Degree at Saranathan College of Engineering, Trichy, India with a GPA of 7.54 out of 10\",\n",
       "  'education',\n",
       "  'salary',\n",
       "  '2019-04-29 21:53:05.958047')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbDelete(query):\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute(query) #\"DELETE FROM conversations\"\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Hi', 'Hi welcome', '', '', '2019-04-27 19:38:04.293500'),\n",
       " (2,\n",
       "  'jon',\n",
       "  \"Hi Jon, Nice to meet you. You can ask questions to know about Raja Singh's professional career.\",\n",
       "  '',\n",
       "  '',\n",
       "  '2019-04-27 19:42:39.253586'),\n",
       " (2,\n",
       "  ' When will he complete his master',\n",
       "  'His expected graduation date is May, 2020',\n",
       "  'master',\n",
       "  '',\n",
       "  '2019-04-27 19:42:51.152003')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dbCreate()\n",
    "#dbSurveyCreate()\n",
    "#dbInsert(0,\"Hi\",\"Hi welcome\",\"\",\"\")\n",
    "#dbDelete(\"DELETE FROM conversations\")\n",
    "#dbDelete(\"DROP TABLE survey\")\n",
    "dbSelectAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbSelectAllSurvey' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f4c3c149cb52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdbSelectAllSurvey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dbSelectAllSurvey' is not defined"
     ]
    }
   ],
   "source": [
    "dbSelectAllSurvey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbSelectAll():\n",
    "    \n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''SELECT * FROM conversations''')\n",
    "    all_rows = c.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('resume.db')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbSelectAllSurvey():\n",
    "    \n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''SELECT * FROM survey''')\n",
    "    all_rows = c.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbCreate():\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS conversations (sessionId integer, userMessage text, botResponse text, responseContext text, previousResponseContext text, insertedDate timestamp)''')\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbSurveyCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbSurveyCreate():\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS survey (sessionId integer, userMessage text, botResponse text, rating text, insertedDate timestamp)''')\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbInsertSurvey(sessionId,userMessage,botResponse,rating):\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    insertValues = (sessionId,userMessage,botResponse,rating,datetime.datetime.now())\n",
    "    print(insertValues)\n",
    "    print(c.execute('''INSERT INTO survey VALUES (?,?,?,?,?)''',insertValues))\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbInsert(sessionId,userMessage,botResponse,respContext,prevContext):\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    if sessionId == None or sessionId == '':\n",
    "        c.execute('''SELECT MAX(sessionId) FROM conversations''')\n",
    "        sessionId = c.fetchone()[0]+1\n",
    "    elif sessionId == 0:\n",
    "        sessionId = 1\n",
    "\n",
    "    insertValues = (sessionId,userMessage,botResponse,respContext,prevContext,datetime.datetime.now())\n",
    "    print(insertValues)\n",
    "    c.execute('''INSERT INTO conversations VALUES (?,?,?,?,?,?)''',insertValues)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbSelect(sessionId):\n",
    "    session = (sessionId,)\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''SELECT * FROM conversations where sessionId = ?''',session)\n",
    "    all_rows = c.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2),token_pattern=r'\\b\\w+\\b',min_df=0)\n",
    "tfTransformer = TfidfTransformer(use_idf = True)\n",
    "#svmClassifier = svm.SVC(kernel='linear', C = 1.0,probability=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(string.punctuation)\n",
    "stopwords.remove('not')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "classes = []\n",
    "documents = []\n",
    "intents = ''\n",
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignoreWords = ['not','i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'when', 'where', 'why', 'how', 'don', \"don't\", 'should', \"should've\", \"?\"]\n",
    "for word in ignoreWords:\n",
    "    stopwords.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIntents():\n",
    "    \n",
    "    with open('profile.json') as json_data:\n",
    "        intents = json.load(json_data)\n",
    "    return intents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(summary):\n",
    "    summary = summary.replace('*','').replace('-',' ').replace('/',' ').replace(\"'\",' ')\n",
    "    tokens_summary = [str.lower().strip(string.punctuation) for str in summary.split() if str not in stopwords]\n",
    "    #tokens_summary = [str.lower().strip(string.punctuation) for str in summary.split()]\n",
    "    lemma_summary = [lemmatizer.lemmatize(token) for token in tokens_summary if len(token) > 0]\n",
    "    #for word in lemma_summary:\n",
    "    #    wordList.append(word)\n",
    "    return(' '.join(word for word in lemma_summary))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = []\n",
    "intents = loadIntents()['intents']\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        documents.append((pattern, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "output_empty = [0] * len(classes)\n",
    "for doc in documents:\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    output.append(output_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = vectorizer.fit_transform([cleanText(pattern) for pattern,tag in documents])\n",
    "#Y = tfTransformer.fit_transform(X)\n",
    "#svmClassifier.fit(Y, list(tag for pattern,tag in documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7999  | total loss: \u001b[1m\u001b[32m0.39389\u001b[0m\u001b[0m | time: 0.033s\n",
      "| Adam | epoch: 1000 | loss: 0.39389 -- iter: 56/58\n",
      "Training Step: 8000  | total loss: \u001b[1m\u001b[32m0.35881\u001b[0m\u001b[0m | time: 0.038s\n",
      "| Adam | epoch: 1000 | loss: 0.35881 -- iter: 58/58\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None,len(Y.toarray().tolist()[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(Y.toarray().tolist(), output, n_epoch=1000, batch_size=8)\n",
    "#model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseMsg = ''\n",
    "tag = ''\n",
    "context = ''\n",
    "dataType = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(actualMessage,previousContext):\n",
    "    message = cleanText(actualMessage)\n",
    "    test_Y = vectorizer.transform([message])\n",
    "    #test_Y = tfTransformer.transform(test_X)\n",
    "    \n",
    "    ft = vectorizer.get_feature_names() \n",
    "    result = list(map(lambda row:dict(zip(ft,row)),test_Y.toarray()))\n",
    "    #print(result)\n",
    "    #print(list(result[0].values()))\n",
    "    result_array = model.predict([list(result[0].values())]).tolist()[0]\n",
    "    for item,score in zip(classes,result_array):\n",
    "        print(item+': '+str(score))\n",
    "    \n",
    "    if max(result_array) > 0.4:\n",
    "        intentTag = classes[result_array.index(max(result_array))]\n",
    "    else:\n",
    "        intentTag = 'unknown'\n",
    "    \n",
    "    \n",
    "    #predicted_svm = svmClassifier.predict(test_Y)\n",
    "    #intentTag = predicted_svm[0]\n",
    "    \n",
    "    for intent in intents:\n",
    "        if intent['tag'] == intentTag:\n",
    "            responseMsg = intent['responses'][0]\n",
    "            #print(\"Response:  \"+responseMsg)\n",
    "            tag = intent['tag']\n",
    "            print(\"Tag:  \"+tag)\n",
    "            context = intent['context']\n",
    "            print(\"Context:  \"+context)\n",
    "            dataType = intent['type']\n",
    "            print(\"Data Type:  \"+dataType)\n",
    "            \n",
    "    \n",
    "    #if tag == 'unknown' or tag == 'master' or tag == 'bachelor':\n",
    "    pos_tokens = nltk.pos_tag(nltk.word_tokenize(actualMessage.lower()))\n",
    "    print(pos_tokens)\n",
    "    print(previousContext)\n",
    "    if (intentTag == 'unknown' and previousContext == 'master') or (context == 'master'):\n",
    "        for word,token in pos_tokens:\n",
    "            if((token == 'WRB' and word=='where') or (word=='location')):\n",
    "                responseMsg = intents[5]['specifics'][0]['location']\n",
    "            elif(token=='WDT'):\n",
    "                responseMsg = intents[5]['specifics'][0]['university']\n",
    "            elif((token == 'WRB' and word=='when') or (word == 'year')) :\n",
    "                responseMsg = intents[5]['specifics'][0]['year'] \n",
    "            elif(word == 'gpa'):\n",
    "                responseMsg = intents[5]['specifics'][0]['gpa'] \n",
    "            elif(word == 'major'):\n",
    "                responseMsg = intents[5]['specifics'][0]['major'] \n",
    "        tag = previousContext\n",
    "    if (intentTag == 'unknown' and previousContext == 'bachelor') or (context == 'bachelor'):\n",
    "        for word,token in pos_tokens:\n",
    "            if((token == 'WRB' and word=='where') or (word=='location')):\n",
    "                responseMsg = intents[4]['specifics'][0]['location']\n",
    "            elif(token=='WDT'):\n",
    "                responseMsg = intents[4]['specifics'][0]['university']\n",
    "            elif((token == 'WRB' and word=='when') or (word == 'year')) :\n",
    "                responseMsg = intents[4]['specifics'][0]['year'] \n",
    "            elif(word == 'gpa'):\n",
    "                responseMsg = intents[4]['specifics'][0]['gpa'] \n",
    "            elif(word == 'major'):\n",
    "                responseMsg = intents[4]['specifics'][0]['major'] \n",
    "        tag = previousContext\n",
    "            \n",
    "    print(\"Response:  \"+responseMsg)\n",
    "    return (responseMsg,tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bachelor: 0.9866346120834351\n",
      "education: 0.00383388833142817\n",
      "goodbye: 1.243123620042752e-06\n",
      "greeting: 3.006251176884689e-07\n",
      "master: 0.004805710632354021\n",
      "thanks: 0.0044678617268800735\n",
      "unknown: 0.00025631138123571873\n",
      "Tag:  bachelor\n",
      "Context:  bachelor\n",
      "Data Type:  data\n",
      "[('tell', 'NN'), ('about', 'IN'), ('his', 'PRP$'), ('bachelor', 'NN'), (\"'s\", 'POS'), ('education', 'NN')]\n",
      "master\n",
      "Response:  Bachelor's Degree - Saranathan College of Engineering, Trichy, India\n",
      "master\n"
     ]
    }
   ],
   "source": [
    "message = \"Tell about his bachelor's education\"\n",
    "response, previousContext = getResponse(message,previousContext)\n",
    "print(previousContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP')]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(message.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', 'not', 'know', 'master', 'degree']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualMessage = \"do not you know about his master degree\"\n",
    "words = actualMessage.split(' ')\n",
    "pos_tokens = nltk.pos_tag(nltk.word_tokenize(actualMessage.lower()))\n",
    "pos_tokens\n",
    "[word for word,tag in nltk.pos_tag(nltk.word_tokenize(actualMessage.lower())) if tag not in ['PRP','IN','PRP$','TO','UH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'which', 'university', 'did', 'he', 'do', 'his', 'master']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_summary = [lemmatizer.lemmatize(token) for token in actualMessage.split() if len(token) > 0]\n",
    "lemma_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word,tag in pos_tokens  if 'which' in word and 'he' in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = loadIntents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('next', 'JJ'), ('project', 'NN')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"next project\"\n",
    "nltk.pos_tag(nltk.word_tokenize(message.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "#[(i, i.label_, i.label) for i in nlp_obama.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_obama = nlp(\"tell about anyone projects\")\n",
    "ner_tags = [(i, i.label_, i.label) for i in nlp_obama.ents]\n",
    "ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for text, ner, label in ner_tags:\n",
    "    for key,value in cardinal_tags.items():\n",
    "        if str(text).lower() in value:\n",
    "            print(key)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinal_tags = {1:['one',1,'first','1st'],2:['two',2,'second','2nd'],3:['three',3,'third','3rd'],4:['four',4,'4th','fourth']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 1, 'first', '1st']\n",
      "['two', 2, 'second', '2nd']\n",
      "['three', 3, 'third', '3rd']\n",
      "['four', 4, '4th', 'fourth']\n"
     ]
    }
   ],
   "source": [
    "for key,value in cardinal_tags.items():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
