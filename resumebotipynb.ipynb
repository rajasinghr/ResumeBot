{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "#import tflearn\n",
    "#import tensorflow as tf\n",
    "import random\n",
    "import nltk.corpus\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from flask import Flask, request, Response, render_template, jsonify\n",
    "import json\n",
    "import string\n",
    "import pickle\n",
    "from os import listdir\n",
    "import os\n",
    "import sqlite3\n",
    "import datetime\n",
    "import time\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbDelete(query):\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute(query) #\"DELETE FROM conversations\"\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Hi', 'Hi welcome', '', '', '2019-04-27 19:38:04.293500'),\n",
       " (2,\n",
       "  'jon',\n",
       "  \"Hi Jon, Nice to meet you. You can ask questions to know about Raja Singh's professional career.\",\n",
       "  '',\n",
       "  '',\n",
       "  '2019-04-27 19:42:39.253586'),\n",
       " (2,\n",
       "  ' When will he complete his master',\n",
       "  'His expected graduation date is May, 2020',\n",
       "  'master',\n",
       "  '',\n",
       "  '2019-04-27 19:42:51.152003')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dbCreate()\n",
    "#dbSurveyCreate()\n",
    "#dbInsert(0,\"Hi\",\"Hi welcome\",\"\",\"\")\n",
    "#dbDelete(\"DELETE FROM conversations\")\n",
    "#dbDelete(\"DROP TABLE survey\")\n",
    "dbSelectAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  'jon',\n",
       "  \"Hi Jon, Nice to meet you. You can ask questions to know about Raja Singh's professional career.\",\n",
       "  'Appropriate',\n",
       "  '2019-04-27 19:42:40.866898'),\n",
       " (2,\n",
       "  'when will he complete his master',\n",
       "  'His expected graduation date is May, 2020',\n",
       "  'Appropriate',\n",
       "  '2019-04-27 19:42:53.288662')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbSelectAllSurvey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbSelectAll():\n",
    "    \n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''SELECT * FROM conversations''')\n",
    "    all_rows = c.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('resume.db')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbSelectAllSurvey():\n",
    "    \n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''SELECT * FROM survey''')\n",
    "    all_rows = c.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbCreate():\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS conversations (sessionId integer, userMessage text, botResponse text, responseContext text, previousResponseContext text, insertedDate timestamp)''')\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbSurveyCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbSurveyCreate():\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS survey (sessionId integer, userMessage text, botResponse text, rating text, insertedDate timestamp)''')\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbInsertSurvey(sessionId,userMessage,botResponse,rating):\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    insertValues = (sessionId,userMessage,botResponse,rating,datetime.datetime.now())\n",
    "    print(insertValues)\n",
    "    print(c.execute('''INSERT INTO survey VALUES (?,?,?,?,?)''',insertValues))\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbInsert(sessionId,userMessage,botResponse,respContext,prevContext):\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    if sessionId == None or sessionId == '':\n",
    "        c.execute('''SELECT MAX(sessionId) FROM conversations''')\n",
    "        sessionId = c.fetchone()[0]+1\n",
    "    elif sessionId == 0:\n",
    "        sessionId = 1\n",
    "\n",
    "    insertValues = (sessionId,userMessage,botResponse,respContext,prevContext,datetime.datetime.now())\n",
    "    print(insertValues)\n",
    "    c.execute('''INSERT INTO conversations VALUES (?,?,?,?,?,?)''',insertValues)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbSelect(sessionId):\n",
    "    session = (sessionId,)\n",
    "    conn = sqlite3.connect('resume.db')\n",
    "    c = conn.cursor()\n",
    "    c.execute('''SELECT * FROM conversations where sessionId = ?''',session)\n",
    "    all_rows = c.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2),token_pattern=r'\\b\\w+\\b',min_df=0)\n",
    "tfTransformer = TfidfTransformer(use_idf = True)\n",
    "#svmClassifier = svm.SVC(kernel='linear', C = 1.0,probability=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(string.punctuation)\n",
    "stopwords.remove('not')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "classes = []\n",
    "documents = []\n",
    "intents = ''\n",
    "output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignoreWords = ['not','i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'when', 'where', 'why', 'how', 'don', \"don't\", 'should', \"should've\", \"?\"]\n",
    "for word in ignoreWords:\n",
    "    stopwords.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIntents():\n",
    "    \n",
    "    with open('profile.json') as json_data:\n",
    "        intents = json.load(json_data)\n",
    "    return intents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(summary):\n",
    "    summary = summary.replace('*','').replace('-',' ').replace('/',' ').replace(\"'\",' ')\n",
    "    tokens_summary = [str.lower().strip(string.punctuation) for str in summary.split() if str not in stopwords]\n",
    "    #tokens_summary = [str.lower().strip(string.punctuation) for str in summary.split()]\n",
    "    lemma_summary = [lemmatizer.lemmatize(token) for token in tokens_summary if len(token) > 0]\n",
    "    #for word in lemma_summary:\n",
    "    #    wordList.append(word)\n",
    "    return(' '.join(word for word in lemma_summary))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classes = []\n",
    "intents = loadIntents()['intents']\n",
    "for intent in intents:\n",
    "    for pattern in intent['patterns']:\n",
    "        documents.append((pattern, intent['tag']))\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "output_empty = [0] * len(classes)\n",
    "for doc in documents:\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    output.append(output_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = vectorizer.fit_transform([cleanText(pattern) for pattern,tag in documents])\n",
    "#Y = tfTransformer.fit_transform(X)\n",
    "#svmClassifier.fit(Y, list(tag for pattern,tag in documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7999  | total loss: \u001b[1m\u001b[32m0.39389\u001b[0m\u001b[0m | time: 0.033s\n",
      "| Adam | epoch: 1000 | loss: 0.39389 -- iter: 56/58\n",
      "Training Step: 8000  | total loss: \u001b[1m\u001b[32m0.35881\u001b[0m\u001b[0m | time: 0.038s\n",
      "| Adam | epoch: 1000 | loss: 0.35881 -- iter: 58/58\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None,len(Y.toarray().tolist()[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(Y.toarray().tolist(), output, n_epoch=1000, batch_size=8)\n",
    "#model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseMsg = ''\n",
    "tag = ''\n",
    "context = ''\n",
    "dataType = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(actualMessage,previousContext):\n",
    "    message = cleanText(actualMessage)\n",
    "    test_Y = vectorizer.transform([message])\n",
    "    #test_Y = tfTransformer.transform(test_X)\n",
    "    \n",
    "    ft = vectorizer.get_feature_names() \n",
    "    result = list(map(lambda row:dict(zip(ft,row)),test_Y.toarray()))\n",
    "    #print(result)\n",
    "    #print(list(result[0].values()))\n",
    "    result_array = model.predict([list(result[0].values())]).tolist()[0]\n",
    "    for item,score in zip(classes,result_array):\n",
    "        print(item+': '+str(score))\n",
    "    \n",
    "    if max(result_array) > 0.4:\n",
    "        intentTag = classes[result_array.index(max(result_array))]\n",
    "    else:\n",
    "        intentTag = 'unknown'\n",
    "    \n",
    "    \n",
    "    #predicted_svm = svmClassifier.predict(test_Y)\n",
    "    #intentTag = predicted_svm[0]\n",
    "    \n",
    "    for intent in intents:\n",
    "        if intent['tag'] == intentTag:\n",
    "            responseMsg = intent['responses'][0]\n",
    "            #print(\"Response:  \"+responseMsg)\n",
    "            tag = intent['tag']\n",
    "            print(\"Tag:  \"+tag)\n",
    "            context = intent['context']\n",
    "            print(\"Context:  \"+context)\n",
    "            dataType = intent['type']\n",
    "            print(\"Data Type:  \"+dataType)\n",
    "            \n",
    "    \n",
    "    #if tag == 'unknown' or tag == 'master' or tag == 'bachelor':\n",
    "    pos_tokens = nltk.pos_tag(nltk.word_tokenize(actualMessage.lower()))\n",
    "    print(pos_tokens)\n",
    "    print(previousContext)\n",
    "    if (intentTag == 'unknown' and previousContext == 'master') or (context == 'master'):\n",
    "        for word,token in pos_tokens:\n",
    "            if((token == 'WRB' and word=='where') or (word=='location')):\n",
    "                responseMsg = intents[5]['specifics'][0]['location']\n",
    "            elif(token=='WDT'):\n",
    "                responseMsg = intents[5]['specifics'][0]['university']\n",
    "            elif((token == 'WRB' and word=='when') or (word == 'year')) :\n",
    "                responseMsg = intents[5]['specifics'][0]['year'] \n",
    "            elif(word == 'gpa'):\n",
    "                responseMsg = intents[5]['specifics'][0]['gpa'] \n",
    "            elif(word == 'major'):\n",
    "                responseMsg = intents[5]['specifics'][0]['major'] \n",
    "        tag = previousContext\n",
    "    if (intentTag == 'unknown' and previousContext == 'bachelor') or (context == 'bachelor'):\n",
    "        for word,token in pos_tokens:\n",
    "            if((token == 'WRB' and word=='where') or (word=='location')):\n",
    "                responseMsg = intents[4]['specifics'][0]['location']\n",
    "            elif(token=='WDT'):\n",
    "                responseMsg = intents[4]['specifics'][0]['university']\n",
    "            elif((token == 'WRB' and word=='when') or (word == 'year')) :\n",
    "                responseMsg = intents[4]['specifics'][0]['year'] \n",
    "            elif(word == 'gpa'):\n",
    "                responseMsg = intents[4]['specifics'][0]['gpa'] \n",
    "            elif(word == 'major'):\n",
    "                responseMsg = intents[4]['specifics'][0]['major'] \n",
    "        tag = previousContext\n",
    "            \n",
    "    print(\"Response:  \"+responseMsg)\n",
    "    return (responseMsg,tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bachelor: 0.9866346120834351\n",
      "education: 0.00383388833142817\n",
      "goodbye: 1.243123620042752e-06\n",
      "greeting: 3.006251176884689e-07\n",
      "master: 0.004805710632354021\n",
      "thanks: 0.0044678617268800735\n",
      "unknown: 0.00025631138123571873\n",
      "Tag:  bachelor\n",
      "Context:  bachelor\n",
      "Data Type:  data\n",
      "[('tell', 'NN'), ('about', 'IN'), ('his', 'PRP$'), ('bachelor', 'NN'), (\"'s\", 'POS'), ('education', 'NN')]\n",
      "master\n",
      "Response:  Bachelor's Degree - Saranathan College of Engineering, Trichy, India\n",
      "master\n"
     ]
    }
   ],
   "source": [
    "message = \"Tell about his bachelor's education\"\n",
    "response, previousContext = getResponse(message,previousContext)\n",
    "print(previousContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', 'WRB'), ('are', 'VBP'), ('you', 'PRP')]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(message.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', 'not', 'know', 'master', 'degree']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualMessage = \"do not you know about his master degree\"\n",
    "words = actualMessage.split(' ')\n",
    "pos_tokens = nltk.pos_tag(nltk.word_tokenize(actualMessage.lower()))\n",
    "pos_tokens\n",
    "[word for word,tag in nltk.pos_tag(nltk.word_tokenize(actualMessage.lower())) if tag not in ['PRP','IN','PRP$','TO','UH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'which', 'university', 'did', 'he', 'do', 'his', 'master']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_summary = [lemmatizer.lemmatize(token) for token in actualMessage.split() if len(token) > 0]\n",
    "lemma_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word,tag in pos_tokens  if 'which' in word and 'he' in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 'IN'),\n",
       " ('which', 'WDT'),\n",
       " ('university', 'NN'),\n",
       " ('did', 'VBD'),\n",
       " ('he', 'PRP'),\n",
       " ('do', 'VB'),\n",
       " ('his', 'PRP$'),\n",
       " ('master', 'NN')]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'greeting',\n",
       "  'patterns': ['Hi',\n",
       "   'How are you',\n",
       "   'Is anyone there?',\n",
       "   'Hello',\n",
       "   'Good day',\n",
       "   'Hey, How are you doing?'],\n",
       "  'responses': ['Hello, thanks for visiting',\n",
       "   'Good to see you',\n",
       "   'Hi there, how can I help?'],\n",
       "  'context': '',\n",
       "  'type': ''},\n",
       " {'tag': 'goodbye',\n",
       "  'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
       "  'responses': ['See you later, thanks for visiting',\n",
       "   'Have a nice day',\n",
       "   'Bye! Come back again soon.'],\n",
       "  'context': '',\n",
       "  'type': ''},\n",
       " {'tag': 'thanks',\n",
       "  'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n",
       "  'responses': ['Happy to help!', 'Any time!', 'My pleasure'],\n",
       "  'context': '',\n",
       "  'type': ''},\n",
       " {'tag': 'education',\n",
       "  'patterns': ['Tell about your educational qualifications',\n",
       "   'education details of him',\n",
       "   'Tell about his education'],\n",
       "  'responses': [\"Master's Degree - University of South Florida, Tampa, Florida. \\nBachelor's Degree - Saranathan College of Engineering, Trichy, India\"],\n",
       "  'context': 'education',\n",
       "  'type': 'list'},\n",
       " {'tag': 'bachelor',\n",
       "  'patterns': [\"Tell about his bachelor's education\",\n",
       "   'which year did he complete his bachelor',\n",
       "   'When did he complete',\n",
       "   'where did he complete his bachelor',\n",
       "   'what is his GPA in bachelor',\n",
       "   'In which location did he do his bachelor',\n",
       "   'bachelor degree details'],\n",
       "  'responses': [\"Bachelor's Degree - Saranathan College of Engineering, Trichy, India\"],\n",
       "  'specifics': [{'year': 'May, 2014',\n",
       "    'location': 'Trichy, Tamilnadu, India',\n",
       "    'major': 'Electronics and Communication Engineering'}],\n",
       "  'context': 'bachelor',\n",
       "  'type': 'data'},\n",
       " {'tag': 'master',\n",
       "  'patterns': [\"Tell about his master's education\",\n",
       "   'which year did he complete his master degree',\n",
       "   'When did he complete',\n",
       "   'what is his GPA in masters',\n",
       "   \"where did he complete his master's\",\n",
       "   'In which location did he do his master education',\n",
       "   'master degree details'],\n",
       "  'responses': [\"Master's Degree - University of South Florida, Tampa, Florida\"],\n",
       "  'specifics': [{'year': 'May, 2020',\n",
       "    'location': 'Tampa, Florida',\n",
       "    'major': 'Business Analytics and Information Systems'}],\n",
       "  'context': 'master',\n",
       "  'type': 'data'},\n",
       " {'tag': 'unknown',\n",
       "  'patterns': ['where did he do', 'when did he complete', 'in which location'],\n",
       "  'responses': ['Please be specific, I am newly employed'],\n",
       "  'context': '',\n",
       "  'type': ''}]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 'skills',\n",
       " 'patterns': ['what are your core skills',\n",
       "  'what are your primary skills',\n",
       "  'what is your primary skillset'],\n",
       " 'responses': ['My primary skills are Python, Big Data, Tableau, Machine Learning'],\n",
       " 'specifics': [{'reporting': ['I have experience on reporting tooks like Tableau, as a part of my curriculum and have done project as well'],\n",
       "   'big data': ['I have knowledge and experience on working in Hadoop, PySpark and Hive'],\n",
       "   'machine learning': ['I have the knowledge of building machine learning models like Neural networks, SVM, Ensembles']}],\n",
       " 'context': 'skills',\n",
       " 'type': 'data'}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intents = loadIntents()['intents']\n",
    "intents[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-88ef7961718e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcorrect_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpelling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Python\\Python37\\lib\\site-packages\\pattern\\text\\__init__.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__repr__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python37\\lib\\site-packages\\pattern\\text\\__init__.py\u001b[0m in \u001b[0;36m_lazy\u001b[1;34m(self, method, *args)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \"\"\"\n\u001b[0;32m    367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Python37\\lib\\site-packages\\pattern\\text\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2621\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2622\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2623\u001b[1;33m             \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2625\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from pattern.en import Spelling\n",
    "\n",
    "word = \"amazzziiing\"\n",
    "\n",
    "correct_word = Spelling(word) \n",
    "print(correct_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
